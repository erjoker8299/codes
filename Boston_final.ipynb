{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c1df6f",
   "metadata": {},
   "source": [
    "Name: Gauri Kailas Bankar (BE_A_66)\n",
    "\n",
    "Problem Statement: Linear regression by using Deep Neural network: Implement Boston housing price prediction problem by Linear regression using Deep Neural network. Use Boston House price prediction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9ec2b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import boston_housing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06bc6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x,train_y),(test_x,test_y)=boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c288e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"C:/Users/lenovo/Desktop/Komal/Datasets/Boston.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62006f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     crim    zn  indus  chas    nox     rm   age     dis  rad  \\\n",
       "0           1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1   \n",
       "1           2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2   \n",
       "2           3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2   \n",
       "3           4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3   \n",
       "4           5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3   \n",
       "\n",
       "   tax  ptratio   black  lstat  medv  \n",
       "0  296     15.3  396.90   4.98  24.0  \n",
       "1  242     17.8  396.90   9.14  21.6  \n",
       "2  242     17.8  392.83   4.03  34.7  \n",
       "3  222     18.7  394.63   2.94  33.4  \n",
       "4  222     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97dfa28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>253.500000</td>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>146.213884</td>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>127.250000</td>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>253.500000</td>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>379.750000</td>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        crim          zn       indus        chas         nox  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean   253.500000    3.613524   11.363636   11.136779    0.069170    0.554695   \n",
       "std    146.213884    8.601545   23.322453    6.860353    0.253994    0.115878   \n",
       "min      1.000000    0.006320    0.000000    0.460000    0.000000    0.385000   \n",
       "25%    127.250000    0.082045    0.000000    5.190000    0.000000    0.449000   \n",
       "50%    253.500000    0.256510    0.000000    9.690000    0.000000    0.538000   \n",
       "75%    379.750000    3.677083   12.500000   18.100000    0.000000    0.624000   \n",
       "max    506.000000   88.976200  100.000000   27.740000    1.000000    0.871000   \n",
       "\n",
       "               rm         age         dis         rad         tax     ptratio  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     6.284634   68.574901    3.795043    9.549407  408.237154   18.455534   \n",
       "std      0.702617   28.148861    2.105710    8.707259  168.537116    2.164946   \n",
       "min      3.561000    2.900000    1.129600    1.000000  187.000000   12.600000   \n",
       "25%      5.885500   45.025000    2.100175    4.000000  279.000000   17.400000   \n",
       "50%      6.208500   77.500000    3.207450    5.000000  330.000000   19.050000   \n",
       "75%      6.623500   94.075000    5.188425   24.000000  666.000000   20.200000   \n",
       "max      8.780000  100.000000   12.126500   24.000000  711.000000   22.000000   \n",
       "\n",
       "            black       lstat        medv  \n",
       "count  506.000000  506.000000  506.000000  \n",
       "mean   356.674032   12.653063   22.532806  \n",
       "std     91.294864    7.141062    9.197104  \n",
       "min      0.320000    1.730000    5.000000  \n",
       "25%    375.377500    6.950000   17.025000  \n",
       "50%    391.440000   11.360000   21.200000  \n",
       "75%    396.225000   16.955000   25.000000  \n",
       "max    396.900000   37.970000   50.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf62108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  506 non-null    int64  \n",
      " 1   crim        506 non-null    float64\n",
      " 2   zn          506 non-null    float64\n",
      " 3   indus       506 non-null    float64\n",
      " 4   chas        506 non-null    int64  \n",
      " 5   nox         506 non-null    float64\n",
      " 6   rm          506 non-null    float64\n",
      " 7   age         506 non-null    float64\n",
      " 8   dis         506 non-null    float64\n",
      " 9   rad         506 non-null    int64  \n",
      " 10  tax         506 non-null    int64  \n",
      " 11  ptratio     506 non-null    float64\n",
      " 12  black       506 non-null    float64\n",
      " 13  lstat       506 non-null    float64\n",
      " 14  medv        506 non-null    float64\n",
      "dtypes: float64(11), int64(4)\n",
      "memory usage: 59.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aab386d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     ptratio   black  lstat  medv  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1c401",
   "metadata": {},
   "source": [
    "Split Dataset for Trainning and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9f54aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Spliting target variable and independent variables\n",
    "# x = df.drop(['medv'], axis = 1)\n",
    "# y = df['medv']\n",
    "\n",
    "# train_x,test_x,train_y,test_y = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea8b7637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_X Size :  (404, 13)\n",
      "Test_X Size :  (102, 13)\n",
      "Train_Y Size :  (404,)\n",
      "Test_Y Size :  (102,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train_X Size : \", train_x.shape)\n",
    "print(\"Test_X Size : \", test_x.shape)\n",
    "print(\"Train_Y Size : \", train_y.shape)  #actual train output\n",
    "print(\"Test_Y Size : \", test_y.shape)    #actual test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "222eadc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data for preprocessing \n",
    "train_x = preprocessing.normalize(train_x)\n",
    "test_x = preprocessing.normalize(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74812a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# # Scale the features using StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9db6c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76033dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "def house_prediction_model():\n",
    "    model=Sequential()\n",
    "    \n",
    "    #add layers\n",
    "    model.add(Dense(128,activation='relu',input_shape=(train_x[0].shape))) #1st layer\n",
    "    model.add(Dense(64,activation='relu')) #2nd layer\n",
    "    model.add(Dense(32,activation='relu')) #3rd layer\n",
    "    model.add(Dense(1)) #last layer\n",
    "    \n",
    "    #compile the model\n",
    "    model.compile(optimizer='adam',loss='mse',metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04d7a2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "404/404 [==============================] - 4s 6ms/step - loss: 163.4689 - mae: 9.0897 - val_loss: 86.6754 - val_mae: 7.7513\n",
      "Epoch 2/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 65.3750 - mae: 5.5205 - val_loss: 58.8830 - val_mae: 5.5722\n",
      "Epoch 3/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 62.5413 - mae: 5.5605 - val_loss: 56.5188 - val_mae: 5.4713\n",
      "Epoch 4/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 57.9644 - mae: 5.2761 - val_loss: 53.7284 - val_mae: 5.3974\n",
      "Epoch 5/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 58.0991 - mae: 5.3171 - val_loss: 53.3982 - val_mae: 5.5174\n",
      "Epoch 6/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 55.4954 - mae: 5.1644 - val_loss: 54.2779 - val_mae: 5.6265\n",
      "Epoch 7/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 53.3540 - mae: 5.0292 - val_loss: 53.4681 - val_mae: 5.1810\n",
      "Epoch 8/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 50.8743 - mae: 4.8252 - val_loss: 50.1018 - val_mae: 5.3282\n",
      "Epoch 9/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 49.0763 - mae: 4.7300 - val_loss: 52.5073 - val_mae: 5.6313\n",
      "Epoch 10/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 48.6270 - mae: 4.7848 - val_loss: 44.3113 - val_mae: 4.7703\n",
      "Epoch 11/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 45.4529 - mae: 4.6512 - val_loss: 44.0552 - val_mae: 4.6179\n",
      "Epoch 12/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 43.6886 - mae: 4.4681 - val_loss: 58.0430 - val_mae: 5.3505\n",
      "Epoch 13/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 40.7327 - mae: 4.4199 - val_loss: 44.9431 - val_mae: 4.6431\n",
      "Epoch 14/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 39.6152 - mae: 4.2951 - val_loss: 41.0547 - val_mae: 4.9830\n",
      "Epoch 15/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 37.6062 - mae: 4.3149 - val_loss: 40.2077 - val_mae: 5.0275\n",
      "Epoch 16/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 37.7107 - mae: 4.2363 - val_loss: 33.3903 - val_mae: 4.0185\n",
      "Epoch 17/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 35.1039 - mae: 4.2030 - val_loss: 32.7067 - val_mae: 4.1274\n",
      "Epoch 18/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 33.6712 - mae: 4.1553 - val_loss: 31.3151 - val_mae: 4.0285\n",
      "Epoch 19/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 34.0386 - mae: 4.1129 - val_loss: 42.1719 - val_mae: 4.5416\n",
      "Epoch 20/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 32.1442 - mae: 4.0435 - val_loss: 31.4716 - val_mae: 3.9648\n",
      "Epoch 21/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 32.4729 - mae: 4.0997 - val_loss: 29.6332 - val_mae: 3.9735\n",
      "Epoch 22/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 30.7299 - mae: 3.9428 - val_loss: 28.9178 - val_mae: 3.9364\n",
      "Epoch 23/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 28.2551 - mae: 3.8163 - val_loss: 35.1061 - val_mae: 4.8363\n",
      "Epoch 24/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 27.7942 - mae: 3.8295 - val_loss: 32.7266 - val_mae: 4.0136\n",
      "Epoch 25/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 27.4584 - mae: 3.7893 - val_loss: 29.2425 - val_mae: 4.2266\n",
      "Epoch 26/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 25.5939 - mae: 3.6494 - val_loss: 28.9316 - val_mae: 3.8514\n",
      "Epoch 27/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 24.8470 - mae: 3.6502 - val_loss: 27.6956 - val_mae: 3.7992\n",
      "Epoch 28/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 22.9044 - mae: 3.5376 - val_loss: 29.2052 - val_mae: 3.8954\n",
      "Epoch 29/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 24.1569 - mae: 3.6002 - val_loss: 30.3115 - val_mae: 3.9519\n",
      "Epoch 30/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 20.4205 - mae: 3.3935 - val_loss: 30.2629 - val_mae: 4.0895\n",
      "Epoch 31/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 22.2567 - mae: 3.5559 - val_loss: 35.4199 - val_mae: 4.0735\n",
      "Epoch 32/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 21.3835 - mae: 3.3480 - val_loss: 34.8017 - val_mae: 4.2199\n",
      "Epoch 33/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 17.5140 - mae: 3.1325 - val_loss: 26.5941 - val_mae: 3.7407\n",
      "Epoch 34/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 19.7572 - mae: 3.2100 - val_loss: 40.7704 - val_mae: 4.5665\n",
      "Epoch 35/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 21.8775 - mae: 3.3882 - val_loss: 29.7438 - val_mae: 3.9604\n",
      "Epoch 36/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 19.7530 - mae: 3.2024 - val_loss: 36.4113 - val_mae: 4.2315\n",
      "Epoch 37/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 20.8163 - mae: 3.2883 - val_loss: 28.0509 - val_mae: 3.7319\n",
      "Epoch 38/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 18.5738 - mae: 3.1674 - val_loss: 30.5716 - val_mae: 3.8644\n",
      "Epoch 39/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 20.2886 - mae: 3.3103 - val_loss: 35.6196 - val_mae: 4.4977\n",
      "Epoch 40/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 19.2427 - mae: 3.2099 - val_loss: 44.0732 - val_mae: 4.6526\n",
      "Epoch 41/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 17.8334 - mae: 3.0924 - val_loss: 35.8052 - val_mae: 4.2149\n",
      "Epoch 42/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 21.3652 - mae: 3.4058 - val_loss: 33.4553 - val_mae: 4.0705\n",
      "Epoch 43/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 18.8379 - mae: 3.1552 - val_loss: 29.0600 - val_mae: 3.7852\n",
      "Epoch 44/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 18.8636 - mae: 3.0686 - val_loss: 42.4415 - val_mae: 4.6494\n",
      "Epoch 45/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 16.8858 - mae: 2.9508 - val_loss: 30.4690 - val_mae: 3.8492\n",
      "Epoch 46/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 18.6871 - mae: 3.1244 - val_loss: 32.5950 - val_mae: 3.9790\n",
      "Epoch 47/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 17.2158 - mae: 2.9870 - val_loss: 32.2511 - val_mae: 4.0336\n",
      "Epoch 48/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 17.7844 - mae: 3.0485 - val_loss: 35.6006 - val_mae: 4.2165\n",
      "Epoch 49/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 18.2063 - mae: 3.1494 - val_loss: 30.4404 - val_mae: 4.0125\n",
      "Epoch 50/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 17.2928 - mae: 3.0444 - val_loss: 34.3323 - val_mae: 4.0095\n",
      "Epoch 51/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 16.6737 - mae: 2.9488 - val_loss: 32.5091 - val_mae: 3.9329\n",
      "Epoch 52/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 18.1946 - mae: 3.1551 - val_loss: 32.3181 - val_mae: 3.9473\n",
      "Epoch 53/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 17.0307 - mae: 3.0687 - val_loss: 32.2055 - val_mae: 3.9019\n",
      "Epoch 54/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 17.7815 - mae: 3.0331 - val_loss: 33.9824 - val_mae: 4.0757\n",
      "Epoch 55/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 18.3711 - mae: 3.0542 - val_loss: 33.2469 - val_mae: 4.2887\n",
      "Epoch 56/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 17.7612 - mae: 3.0973 - val_loss: 29.1195 - val_mae: 3.6966\n",
      "Epoch 57/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 16.4888 - mae: 3.0003 - val_loss: 37.6001 - val_mae: 4.3320\n",
      "Epoch 58/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 16.3706 - mae: 2.9523 - val_loss: 30.5400 - val_mae: 3.7806\n",
      "Epoch 59/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 14.6928 - mae: 2.8275 - val_loss: 32.2537 - val_mae: 3.9008\n",
      "Epoch 60/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 16.7069 - mae: 2.9687 - val_loss: 30.4917 - val_mae: 3.8823\n",
      "Epoch 61/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 17.4672 - mae: 3.0195 - val_loss: 27.9837 - val_mae: 3.6924\n",
      "Epoch 62/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 18.4775 - mae: 3.0839 - val_loss: 27.4711 - val_mae: 3.8477\n",
      "Epoch 63/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 18.3817 - mae: 3.0984 - val_loss: 29.5580 - val_mae: 3.7027\n",
      "Epoch 64/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 15.4419 - mae: 2.9273 - val_loss: 29.2819 - val_mae: 3.7202\n",
      "Epoch 65/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 17.4321 - mae: 2.9842 - val_loss: 30.7066 - val_mae: 3.7826\n",
      "Epoch 66/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 16.7367 - mae: 2.8928 - val_loss: 32.6081 - val_mae: 3.8899\n",
      "Epoch 67/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 15.3876 - mae: 2.9249 - val_loss: 33.0539 - val_mae: 3.8594\n",
      "Epoch 68/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 17.1497 - mae: 2.9696 - val_loss: 32.3459 - val_mae: 4.0337\n",
      "Epoch 69/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 14.7510 - mae: 2.7546 - val_loss: 30.5724 - val_mae: 3.8260\n",
      "Epoch 70/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 16.7111 - mae: 3.0432 - val_loss: 29.7989 - val_mae: 3.7153\n",
      "Epoch 71/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 15.4207 - mae: 2.8247 - val_loss: 38.9675 - val_mae: 4.3991\n",
      "Epoch 72/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 16.0934 - mae: 2.9247 - val_loss: 33.8184 - val_mae: 3.9402\n",
      "Epoch 73/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 15.5366 - mae: 2.9656 - val_loss: 30.8894 - val_mae: 3.7536\n",
      "Epoch 74/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 15.4184 - mae: 2.8868 - val_loss: 58.4807 - val_mae: 5.4476\n",
      "Epoch 75/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 18.3630 - mae: 3.1347 - val_loss: 34.4815 - val_mae: 4.0397\n",
      "Epoch 76/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 16.0398 - mae: 2.9103 - val_loss: 30.9376 - val_mae: 3.7514\n",
      "Epoch 77/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 16.8426 - mae: 2.9651 - val_loss: 34.3089 - val_mae: 3.9398\n",
      "Epoch 78/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 15.4349 - mae: 2.8605 - val_loss: 46.1595 - val_mae: 4.7932\n",
      "Epoch 79/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 18.0666 - mae: 3.0057 - val_loss: 49.8450 - val_mae: 4.9085\n",
      "Epoch 80/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 16.3932 - mae: 2.9429 - val_loss: 30.5906 - val_mae: 3.7666\n",
      "Epoch 81/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 15.8196 - mae: 2.9141 - val_loss: 30.3118 - val_mae: 3.7960\n",
      "Epoch 82/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 16.7580 - mae: 2.9198 - val_loss: 35.9556 - val_mae: 4.1379\n",
      "Epoch 83/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 16.5703 - mae: 2.9836 - val_loss: 33.0873 - val_mae: 3.8936\n",
      "Epoch 84/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 15.4696 - mae: 2.8539 - val_loss: 38.7491 - val_mae: 4.3606\n",
      "Epoch 85/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 16.9847 - mae: 2.9176 - val_loss: 29.8418 - val_mae: 3.6489\n",
      "Epoch 86/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 14.9978 - mae: 2.8291 - val_loss: 31.6911 - val_mae: 3.7602\n",
      "Epoch 87/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 15.5984 - mae: 2.9045 - val_loss: 37.4846 - val_mae: 4.3848\n",
      "Epoch 88/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 17.6958 - mae: 2.9616 - val_loss: 31.7990 - val_mae: 3.8701\n",
      "Epoch 89/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 14.6179 - mae: 2.7730 - val_loss: 33.3959 - val_mae: 3.9864\n",
      "Epoch 90/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 15.7342 - mae: 2.8931 - val_loss: 28.5915 - val_mae: 3.5898\n",
      "Epoch 91/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 15.9659 - mae: 2.8824 - val_loss: 29.8198 - val_mae: 3.6439\n",
      "Epoch 92/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 14.4362 - mae: 2.7752 - val_loss: 32.5722 - val_mae: 3.8840\n",
      "Epoch 93/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 16.1801 - mae: 2.9253 - val_loss: 54.6845 - val_mae: 5.4856\n",
      "Epoch 94/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 15.4500 - mae: 2.8198 - val_loss: 34.3539 - val_mae: 3.9246\n",
      "Epoch 95/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 15.1856 - mae: 2.8335 - val_loss: 32.0646 - val_mae: 3.7919\n",
      "Epoch 96/100\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 15.0305 - mae: 2.8036 - val_loss: 31.5633 - val_mae: 3.7601\n",
      "Epoch 97/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 16.3464 - mae: 2.9430 - val_loss: 30.6815 - val_mae: 3.7070\n",
      "Epoch 98/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 15.9356 - mae: 2.8430 - val_loss: 38.0433 - val_mae: 4.2759\n",
      "Epoch 99/100\n",
      "404/404 [==============================] - 1s 1ms/step - loss: 16.0002 - mae: 2.8398 - val_loss: 45.4710 - val_mae: 4.8209\n",
      "Epoch 100/100\n",
      "404/404 [==============================] - 1s 2ms/step - loss: 15.9268 - mae: 2.8244 - val_loss: 36.7196 - val_mae: 4.0829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c6d48ed450>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model = house_prediction_model()\n",
    "model.fit(train_x,train_y,epochs=100,batch_size=1,verbose=1,validation_data=(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acbe6eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 36.7196 - mae: 4.0829\n",
      "Mean squared error on test data:  36.71957015991211\n",
      "Mean absolute error on test data:  4.082910060882568\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the test set\n",
    "mse, mae = model.evaluate(test_x, test_y)\n",
    "print('Mean squared error on test data: ', mse)#average squared difference between the predicted and actual values.\n",
    "print('Mean absolute error on test data: ', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be907e6",
   "metadata": {},
   "source": [
    "MAE - MAE measures the average absolute difference between the predicted and actual values. In this context, a lower MAE indicates better performance.\n",
    "MSE - Goal is to minimize the MSE, which measures the average squared difference between the predicted and actual values. A lower MSE indicates better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68be0486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction_result=model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b16c286a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction price:  [9.708938]\n",
      "prediction price:  [18.345547]\n",
      "prediction price:  [22.678823]\n",
      "prediction price:  [43.36912]\n",
      "prediction price:  [25.781448]\n",
      "prediction price:  [19.766232]\n",
      "prediction price:  [32.34054]\n",
      "prediction price:  [24.251825]\n",
      "prediction price:  [18.826866]\n",
      "prediction price:  [21.153168]\n",
      "prediction price:  [15.752611]\n",
      "prediction price:  [18.667212]\n",
      "prediction price:  [16.805626]\n",
      "prediction price:  [40.369804]\n",
      "prediction price:  [18.293339]\n",
      "prediction price:  [21.041836]\n",
      "prediction price:  [23.44604]\n",
      "prediction price:  [21.185171]\n",
      "prediction price:  [19.17523]\n",
      "prediction price:  [31.64114]\n",
      "prediction price:  [11.879501]\n",
      "prediction price:  [14.086919]\n",
      "prediction price:  [20.83587]\n",
      "prediction price:  [17.023033]\n",
      "prediction price:  [22.55328]\n",
      "prediction price:  [26.658041]\n",
      "prediction price:  [28.390856]\n",
      "prediction price:  [31.10016]\n",
      "prediction price:  [11.977646]\n",
      "prediction price:  [22.27579]\n",
      "prediction price:  [20.513054]\n",
      "prediction price:  [13.886726]\n",
      "prediction price:  [38.36581]\n",
      "prediction price:  [22.600914]\n",
      "prediction price:  [17.465714]\n",
      "prediction price:  [10.24218]\n",
      "prediction price:  [15.023482]\n",
      "prediction price:  [15.704014]\n",
      "prediction price:  [19.855698]\n",
      "prediction price:  [28.879005]\n",
      "prediction price:  [24.36058]\n",
      "prediction price:  [26.930578]\n",
      "prediction price:  [16.724567]\n",
      "prediction price:  [35.398014]\n",
      "prediction price:  [38.41615]\n",
      "prediction price:  [22.788445]\n",
      "prediction price:  [29.908775]\n",
      "prediction price:  [18.952473]\n",
      "prediction price:  [32.224274]\n",
      "prediction price:  [22.06289]\n",
      "prediction price:  [33.701344]\n",
      "prediction price:  [18.952536]\n",
      "prediction price:  [12.914325]\n",
      "prediction price:  [16.780724]\n",
      "prediction price:  [37.300453]\n",
      "prediction price:  [28.912477]\n",
      "prediction price:  [14.559467]\n",
      "prediction price:  [38.287594]\n",
      "prediction price:  [42.954132]\n",
      "prediction price:  [25.03825]\n",
      "prediction price:  [26.656023]\n",
      "prediction price:  [18.170437]\n",
      "prediction price:  [13.405963]\n",
      "prediction price:  [19.820204]\n",
      "prediction price:  [26.123901]\n",
      "prediction price:  [24.873905]\n",
      "prediction price:  [15.118019]\n",
      "prediction price:  [25.36787]\n",
      "prediction price:  [13.474785]\n",
      "prediction price:  [10.531258]\n",
      "prediction price:  [28.975567]\n",
      "prediction price:  [26.585793]\n",
      "prediction price:  [25.509914]\n",
      "prediction price:  [14.659661]\n",
      "prediction price:  [23.793537]\n",
      "prediction price:  [20.043425]\n",
      "prediction price:  [21.63981]\n",
      "prediction price:  [22.150476]\n",
      "prediction price:  [37.860424]\n",
      "prediction price:  [11.343246]\n",
      "prediction price:  [20.791914]\n",
      "prediction price:  [41.731537]\n",
      "prediction price:  [18.39216]\n",
      "prediction price:  [16.118532]\n",
      "prediction price:  [20.614243]\n",
      "prediction price:  [17.935524]\n",
      "prediction price:  [22.539152]\n",
      "prediction price:  [20.022888]\n",
      "prediction price:  [21.8716]\n",
      "prediction price:  [39.251675]\n",
      "prediction price:  [18.440243]\n",
      "prediction price:  [21.773272]\n",
      "prediction price:  [21.555443]\n",
      "prediction price:  [28.670578]\n",
      "prediction price:  [38.664665]\n",
      "prediction price:  [18.893515]\n",
      "prediction price:  [41.452366]\n",
      "prediction price:  [53.03138]\n",
      "prediction price:  [23.707191]\n",
      "prediction price:  [59.44805]\n",
      "prediction price:  [30.675865]\n",
      "prediction price:  [18.555733]\n"
     ]
    }
   ],
   "source": [
    "for pred in prediction_result:\n",
    "    print(\"prediction price: \",pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502e1420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
